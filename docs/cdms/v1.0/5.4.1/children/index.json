{
  "title": "Observations quality assessment",
  "text": "This subsection refers to the processes implemented to help NMHSs assess the quality of observations used by their organization. It covers all stages, from the observation site and expertise level of personnel to the final product distributed to users.\n\nThe aim of this subsection is to move towards a more objective way of defining the quality of observations data.",
  "components": [
    "5.4.1.1",
    "5.4.1.2",
    "5.4.1.3",
    "5.4.1.4"
  ],
  "copyright": "World Meteorological Organization, 2014",
  "reference": "WMO-No. 1131",
  "version": "1.0",
  "5.4.1.1": {
    "title": "Siting classification",
    "text": "This component refers to the processes, software, governance mechanisms and analysis that classify sensors according to the rating scale described in the *Guide to Meteorological Instruments and\nMethods of Observation* (WMO-No. 8), Annex 1.B Siting classifications for surface observing stations on land.",
    "classification": "Required"
  },
  "5.4.1.2": {
    "title": "Sustained performance classification",
    "text": "This component refers to the processes, software, governance mechanisms and analysis that classify sensors according to their sustained performance over time.\n\nThe best description found to date on how to determine this classification may be found in Annex III of the final report of the first session of the Commission for Instruments and Methods of Observation Expert Team on Standardization.\n\nNote: A more objective approach to developing this classification for the global WMO community is required.",
    "classification": "Recommended"
  },
  "5.4.1.3": {
    "title": "Multilayer quality flags",
    "text": "This component refers to the processes, software, governance mechanisms and data analysis used to understand and enumerate the quality flags of a specific record of data.\n\nThis will facilitate:\n1. Future analysis that requires data of a specific quality flag value.\n2. Communication on the assessed quality of records.\n\nThe best description to date on how to define this classification may be found in the *Guide to Climatological Practices* (WMO-No. 100), pp. 3\u20138 to 3\u20139. This reference describes a way of flagging quality based on a combination of:\n\n3. Data type (original, corrected, reconstructed or calculated)\n4. Validation stage\n5.  Acquisition method\n\nThis approach is still quite limited. It does not provide a clear way of determining just what level of quality control a record has been subjected to.\n\nWhile the classifications are relevant and relate to the perceived quality of a record, they do not allow for an explicit comparison of data of similar perceived quality.\n\nFor example, the subsection on quality management (5.3.1) describes a series of classifications of tests (without providing actual details). If a record has passed all such tests, can it be considered to be better quality than one that has not passed any test?\n\nObjective quality classifications are required to support a consistent approach within the global WMO community so that data can be:\n\n6. Objectively compared to ensure that data of similar quality can be compared and analysed as required.\n7. Stored and easily retrieved from a climate database. It is becoming increasingly apparent that organizations will need to retain observations at multiple levels of quality from the raw observation through various edit and analysis processes in order to demonstrate the true lineage of a record and explain and justify the changes made to the raw observations.\n\nNote: A more objective approach to determining this classification for the global WMO community is required.",
    "classification": "Required"
  },
  "5.4.1.4": {
    "title": "Climate observation quality classification",
    "text": "This component refers to the processes, software, governance mechanisms and data analysis used to understand and enumerate the quality of a specific record of data relative to an objective index. This index will need to combine a number of criteria relevant to data reliability and quality.\n\nNote: This index has yet to be created. For the purposes of this publication, it is called the climate observation quality classification. However, this name may change. It is envisioned that this index will need to take into account a number of factors, including:\n1. Siting classification\n2. Sustained performance classification\n3. Regular maintenance and calibration of sensor\n4. Sensor reliability\n5. Uncertainty inherent in observations\n6. Observation quality control processes\n7. Multilayer quality flags\n8. Lineage\n9. Homogeneity\n10. Other appropriate factors\n\nSee also the summary of findings of the seventh Data Management Workshop of the European Climate Support Network (ECSN) held at the Danish Meteorological Institute, in particular:\n> Noting that \u201ceverybody\u201d talks about different levels of Quality Control [QC] and (almost) nobody uses the same wording or nomenclature \u2013 it is recommended that an overview of QC nomenclature in ECSN is worked out. It might be considered if such an overview could form the basis for a recommended set of QC wordings. (Kern- Hansen, 2009)",
    "classification": "Optional"
  }
}