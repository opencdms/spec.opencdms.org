<!doctype html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport"
          content="width=device-width, user-scalable=no, initial-scale=1.0, maximum-scale=1.0, minimum-scale=1.0">
    <meta http-equiv="X-UA-Compatible" content="ie=edge">
    <title>CDMS Governance</title>
</head>

<style>
    #wrapper {
        width: 1600px;
        margin: 0 auto;
        padding: 0;
    }

    .content {
        width: 100%;
        overflow: hidden;
        overflow-wrap: break-word;
    }

    table {
        border-collapse: collapse;
        margin-bottom: 30px;
    }

    td {
        border: 1px solid black;
        padding: 0 15px;
    }

    .chapter-title {
        color: #003869;
        border-bottom: 5px solid #a9b4cf;
        padding-bottom: 10px;
    }

    .section-title {
        color: #003869;
    }

    .sub-section-title {
        color: #7489af;
    }

    pre, .cdms-content {
        white-space: pre-wrap;
        white-space: -moz-pre-wrap;
        white-space: -o-pre-wrap;
        word-wrap: break-word;
    }
</style>
<body>
<div id="wrapper">
    <div class="content">
        <table style="width: 100%;">
            <colgroup>
                <col span="1" style="width: 15%;">
                <col span="1" style="width: 70%;">
                <col span="1" style="width: 15%;">
            </colgroup>
            <tbody>


            <tr>
                <td colspan="3">
                    <h4 class="sub-section-title"><span
                            style="padding-right: 10px">5.4.1</span> Observations quality assessment
                    </h4>
                    <div class="cdms-content" style="padding-bottom: 10px;">This subsection refers to the processes implemented to help NMHSs assess the quality of observations used by their organization. It covers all stages, from the observation site and expertise level of personnel to the final product distributed to users.

The aim of this subsection is to move towards a more objective way of defining the quality of observations data.</div>
                </td>
            </tr>
            <tr>
                <td style="background-color: #dff2fd;">5.4.1.1 Siting classification</td>
                <td class="cdms-content">
                    <p>This component refers to the processes, software, governance mechanisms and analysis that classify sensors according to the rating scale described in the <em>Guide to Meteorological Instruments and
Methods of Observation</em> (WMO-No. 8), Annex 1.B Siting classifications for surface observing stations on land.</p>
                </td>
                <td style="background-color: #f3eb72;">Required</td>
            </tr>
            <tr>
                <td style="background-color: #dff2fd;">5.4.1.2 Sustained performance classification</td>
                <td class="cdms-content">
                    <p>This component refers to the processes, software, governance mechanisms and analysis that classify sensors according to their sustained performance over time.</p>
<p>The best description found to date on how to determine this classification may be found in Annex III of the final report of the first session of the Commission for Instruments and Methods of Observation Expert Team on Standardization.</p>
<p>Note: A more objective approach to developing this classification for the global WMO community is required.</p>
                </td>
                <td style="background-color: #b3d386;">Recommended</td>
            </tr>
            <tr>
                <td style="background-color: #dff2fd;">5.4.1.3 Multilayer quality flags</td>
                <td class="cdms-content">
                    <p>This component refers to the processes, software, governance mechanisms and data analysis used to understand and enumerate the quality flags of a specific record of data.</p>
<p>This will facilitate:
1. Future analysis that requires data of a specific quality flag value.
2. Communication on the assessed quality of records.</p>
<p>The best description to date on how to define this classification may be found in the <em>Guide to Climatological Practices</em> (WMO-No. 100), pp. 3–8 to 3–9. This reference describes a way of flagging quality based on a combination of:</p>
<ol>
<li>Data type (original, corrected, reconstructed or calculated)</li>
<li>Validation stage</li>
<li>Acquisition method</li>
</ol>
<p>This approach is still quite limited. It does not provide a clear way of determining just what level of quality control a record has been subjected to.</p>
<p>While the classifications are relevant and relate to the perceived quality of a record, they do not allow for an explicit comparison of data of similar perceived quality.</p>
<p>For example, the subsection on quality management (5.3.1) describes a series of classifications of tests (without providing actual details). If a record has passed all such tests, can it be considered to be better quality than one that has not passed any test?</p>
<p>Objective quality classifications are required to support a consistent approach within the global WMO community so that data can be:</p>
<ol>
<li>Objectively compared to ensure that data of similar quality can be compared and analysed as required.</li>
<li>Stored and easily retrieved from a climate database. It is becoming increasingly apparent that organizations will need to retain observations at multiple levels of quality from the raw observation through various edit and analysis processes in order to demonstrate the true lineage of a record and explain and justify the changes made to the raw observations.</li>
</ol>
<p>Note: A more objective approach to determining this classification for the global WMO community is required.</p>
                </td>
                <td style="background-color: #f3eb72;">Required</td>
            </tr>
            <tr>
                <td style="background-color: #dff2fd;">5.4.1.4 Climate observation quality classification</td>
                <td class="cdms-content">
                    <p>This component refers to the processes, software, governance mechanisms and data analysis used to understand and enumerate the quality of a specific record of data relative to an objective index. This index will need to combine a number of criteria relevant to data reliability and quality.</p>
<p>Note: This index has yet to be created. For the purposes of this publication, it is called the climate observation quality classification. However, this name may change. It is envisioned that this index will need to take into account a number of factors, including:
1. Siting classification
2. Sustained performance classification
3. Regular maintenance and calibration of sensor
4. Sensor reliability
5. Uncertainty inherent in observations
6. Observation quality control processes
7. Multilayer quality flags
8. Lineage
9. Homogeneity
10. Other appropriate factors</p>
<p>See also the summary of findings of the seventh Data Management Workshop of the European Climate Support Network (ECSN) held at the Danish Meteorological Institute, in particular:</p>
<blockquote>
<p>Noting that “everybody” talks about different levels of Quality Control [QC] and (almost) nobody uses the same wording or nomenclature – it is recommended that an overview of QC nomenclature in ECSN is worked out. It might be considered if such an overview could form the basis for a recommended set of QC wordings. (Kern- Hansen, 2009)</p>
</blockquote>
                </td>
                <td style="background-color: #e3e3e3;">Optional</td>
            </tr>
            </tbody>
        </table>

    </div>
</div>
</body>
</html>